.. knowledge_record documentation master file, created by
   sphinx-quickstart on Tue July 4 21:15:34 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

******************
Machine_Learning
******************

ensemble
=====================

änˈsämbəl

分为bagging(减小方差)、boosting(偏差) 和 stacking(改进预测)

bagging和boost
---------------------
| Bagging算法是这样做的：每个分类器都随机从原样本中做有放回的采样，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来。简单的多数投票一般就可以。其代表算法是随机森林。

| Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关。其代表算法是AdaBoost, GBDT。

| Bagging和Boosting的区别（面试准备）
| https://www.cnblogs.com/earendil/p/8872001.html

stacking
--------------------

.. image:: ../../_static/machine_learning/stacking.png
	:align: center
	
关于stacking 的使用
https://blog.csdn.net/Li_yi_chao/article/details/89638009
	

GBDT、Adboost、xgboost
-------------------------
| GBDT与Adboost最主要的区别在于两者如何识别模型的问题。Adaboost用错分数据点来识别问题，通过调整错分数据点的权重来改进模型。GBDT通过负梯度来识别问题，通过计算负梯度来改进模型。

| 推荐GBDT树的深度：6；（横向比较：DecisionTree/RandomForest需要把树的深度调到15或更高）

| 提升树与梯度提升树：利用损失函数的负梯度在当前模型的值，代替提升树算法中的残差的作用


| GBDT 台大林轩田老师讲解视频：
| https://www.youtube.com/watch?v=pTNKUj_1Dw8&list=PL1AVtvtzG0LYN-dOGPYyRrzzyI5fk_D4H&index=31

| 这个文字资料写的不错：
| http://www.52caml.com/head_first_ml/ml-chapter6-boosting-family/

| AdaBoost算法缺点

| 对异常点敏感
| 最终模型无法用概率来解释


| Xgboost 为什么用二阶泰勒展开

| 二阶信息本身就能让梯度收敛更快更准确。这一点在优化算法里的牛顿法里已经证实了。可以简单认为一阶导指引梯度方向，二阶导指引梯度方向如何变化。这是从二阶导本身的性质，也就是为什么要用泰勒二阶展开的角度来说的

| 收敛速度上有提升

| 知乎：最优化问题中，牛顿法为什么比梯度下降法求解需要的迭代次数更少？https://www.zhihu.com/question/19723347

| Xgboost https://juejin.im/post/5d2590e1e51d45106b15ffaa 这篇文章讲的不错


| XGBoost与GBDT有什么不同

| 除了算法上与传统的GBDT有一些不同外，XGBoost还在工程实现上做了大量的优化。总的来说，两者之间的区别和联系可以总结成以下几个方面。
| 1.	GBDT是机器学习算法，XGBoost是该算法的工程实现。
| 2.	在使用CART作为基分类器时，XGBoost显式地加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和
| 3.	GBDT在模型训练时只使用了代价函数的一阶导数信息，XGBoost对代价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数。
| 4.	传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器，比如线性分类器。
| 5.	传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机森林相似的策略，支持对数据进行采样。
| 6.	传统的GBDT没有设计对缺失值进行处理，XGBoost能够自动学习出缺失值的处理策略。


决策树与这些算法框架进行结合所得到的新的算法：

| 1）Bagging + 决策树 = 随机森林
| 2）AdaBoost + 决策树 = 提升树
| 3）Gradient Boosting + 决策树 = GBDT

xgboost怎么给特征评分？

| 在训练的过程中，通过Gini指数选择分离点的特征，一个特征被选中的次数越多，那么该特征评分越高。
| 特征评分可以看成是被用来分离决策树的次数。


基础机器学习算法
========================

Logistics regression
----------------------------
李宏毅视频


.. image:: ../../_static/machine_learning/lr.png
	:align: center
	
| 为什么 logistic regression 的输入特征一般是离散的而不是连续的？
| （1）离散特征的增加和减少都很容易，易于模型的快速迭代。 
| （2）稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展。 
| （3）对异常数据具有较强的鲁棒性。 
| （4）单个特征离散化为 N 个后，每个特征有单独的权重，相当于引入了非线性，增加了模型的表达能力，加大了拟合能力。 
| （5）可以特征交叉，M + N 个特征变为 M * N 个特征，进一步引入非线性，提升表达能力。 
| （6）特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。

PCA
---------------
单层线性神经网络的降维=PCA

核心思想，我的总结：在高维空间中散布着很多点，要找到一条特征向量Eigenvector  第一主成分，使得这些点在投影到这个特征向量上以后是分散的最开的。如何衡量分散程度？
用Var 方差最大来衡量。


数学推导的话：PCA（主成分分析法）中，主成分方向的推导 https://www.bilibili.com/video/BV1ED4y1U7CC?from=search&seid=17109712823241897967
这个真的讲得好！颇像当时在JHU上课时学的讲法

关于点积： 求一个点在一个向量上的投影，就用点积。

所以说Var[aTX]要最大。a是那个特征向量

For any vector  a∈RN 

𝕍𝕒𝕣[aTX]=𝔼[(aTX)(XTa)]=𝔼[aT(XXT)a]Var[aTX]=E[(aTX)(XTa)]=E[aT(XXT)a] 

so

𝕍𝕒𝕣[aTX]=aT𝔼[XXT]a=aTCaVar[aTX]=aTE[XXT]a=aT*C*a  其中C=XT*X 是一个实对称矩阵

We have to maximize this such that  a**2=1也就是aT*a=1,做个单位化  （不然的话，让aT*C*a大，只需要让a越来越大就好） 注意，这里已经做了μ=0的平移变换了

这是一个优化问题，有对a的限制，用拉格朗日乘子法，转化为求 u(a)=aT*C*a - λ(aT*a-1)的最大值

这个是矩阵的求导有点复杂。可以简单的看成 Ca**2-λa**2。求导的话，是求Ca-λa=0 ===> (C-λI)a=0

当 a,λ 分别为C矩阵的特征向量，特征值时，u(a)有极值

这样一来，可以直接求解C的特征向量和特征值，将特征值从大到小排序，所对应的特征向量作为PCA的轴。

关于如何通过一个给定的矩阵求解他的特征向量和特征值，手算的话请看https://blog.csdn.net/Junerror/article/details/80222540

.. image:: ../../_static/machine_learning/特征值的求解.png
	:align: center


JHU上课时画的那个图，长得像loss下降的形式是这个意思。比如说前几个最大的λ的值是10,6,1。那么从三维降维成两维,保留的信息就是(10+6)/(10+6+1)

LDA(Linear Discriminant Analysis)
-----------------------------------------------
核心思想，我的总结：在高维空间中散布着很多点，已知label。要找到一条特征向量Eigenvector，使得这些点在投影到这个特征向量上以后，同一标签的数据间隔最小，不同标签的数据间隔最大。
如何衡量分散程度？用Var 方差最大来衡量。



SVM
-------------
| https://www.bilibili.com/video/BV1ut41197F6?p=14
| 林轩田的 
| 包括李航的统计学习

.. image:: ../../_static/machine_learning/SVM.png
	:align: center
	

.. image:: ../../_static/machine_learning/hinge_loss.png
	:align: center

为什么hinge loss在SVM时代大放异彩，但在神经网络时代就不好用了呢？主要就是因为svm时代我们用的是二分类，通过使用一些小技巧比如1 vs 1、1 vs n
等方式来做多分类问题。而如论文[3]这样直接把hinge loss应用在多分类上的话，当类别数特别大时，会有大量的非目标分数得到优化，
这样每次优化时的梯度幅度不等且非常巨大，极易梯度爆炸。

聚类
-------------
DBSCAN

kmeans

GMM

两种聚类的思想，评价，具体实现

https://www.nowcoder.com/discuss/432266?type=post&order=create&pos=&page=0&channel=666&source_id=search_post

https://www.jianshu.com/p/78e9e1b8553a


贝叶斯
----------------
李航统计学习
	
https://www.zhihu.com/question/19725590/answer/241988854



随机森林
--------------------------------------------

随机森林面试题

1.1 优缺点

| 优点。
| (1)不必担心过度拟合；
| (2)适用于数据集中存在大量未知特征；
| (3)能够估计哪个特征在分类中更重要；
| (4)具有很好的抗噪声能力；
| (5)算法容易理解；
| (6)可以并行处理。

| 缺点。
| （1）对小量数据集和低维数据集的分类不一定可以得到很好的效果。
| （2）执行速度虽然比Boosting等快，但是比单个的决策树慢很多。
| （3）可能会出现一些差异度非常小的树，淹没了一些正确的决策。
| （4）由于树是随机生成的，结果不稳定（kpi值比较大）

| 1.2 生成步骤介绍
| 1、从原始训练数据集中，应用bootstrap方法有放回地随机抽取k个新的自助样本集，并由此构建k棵分类回归树，每次未被抽到的样本组成了Ｋ个袋外数据（out-of-bag,BBB）。
| 2、设有n 个特征，则在每一棵树的每个节点处随机抽取mtry 个特征，通过计算每个特征蕴含的信息量，特征中选择一个最具有分类能力的特征进行节点分裂。
| 3、每棵树最大限度地生长， 不做任何剪裁
| 4、将生成的多棵树组成随机森林， 用随机森林对新的数据进行分类， 分类结果按树分类器投票多少而定。

| 1.3 随机森林与SVM的比较
| （1）不需要调节过多的参数，因为随机森林只需要调节树的数量，而且树的数量一般是越多越好，而其他机器学习算法，比如SVM，有非常多超参数需要调整，如选择最合适的核函数，正则惩罚等。
| （2）分类较为简单、直接。随机森林和支持向量机都是非参数模型（复杂度随着训练模型样本的增加而增大）。相较于一般线性模型，就计算消耗来看，训练非参数模型因此更为耗时耗力。分类树越多，需要更耗时来构建随机森林模型。同样，我们训练出来的支持向量机有很多支持向量，最坏情况为，我们训练集有多少实例，就有多少支持向量。虽然，我们可以使用多类支持向量机，但传统多类分类问题的执行一般是one-vs-all（所谓one-vs-all 就是将binary分类的方法应用到多类分类中。比如我想分成K类，那么就将其中一类作为positive），因此我们还是需要为每个类训练一个支持向量机。相反，决策树与随机深林则可以毫无压力解决多类问题。
| （3）比较容易入手实践。随机森林在训练模型上要更为简单。你很容易可以得到一个又好且具鲁棒性的模型。随机森林模型的复杂度与训练样本和树成正比。支持向量机则需要我们在调参方面做些工作，除此之外，计算成本会随着类增加呈线性增长。
| （4）小数据上，SVM优异，而随机森林对数据需求较大。就经验来说，我更愿意认为支持向量机在存在较少极值的小数据集上具有优势。随机森林则需要更多数据但一般可以得到非常好的且具有鲁棒性的模型。

| 1.4 随机森林不会发生过拟合的原因
| 在建立每一棵决策树的过程中，有两点需要注意-采样与完全分裂。首先是两个随机采样的过程，random forest对输入的数据要进行行、列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。
| 对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。*然后进行列采样，从M 个feature中，选择m个(m << M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一 个分类。*一般很多的决策树算法都一个重要的步骤 - 剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。

| 1.5 随机森林与梯度提升树（GBDT）区别
| 随机森林：决策树+bagging=随机森林
| 梯度提升树：决策树+Boosting=GBDT
| 两者区别在于bagging boosting之间的区别。
| 像神经网络这样为消耗时间的算法，bagging可通过并行节省大量的时间开销
| baging和boosting都可以有效地提高分类的准确性
| baging和boosting都可以有效地提高分类的准确性
| 一些模型中会造成模型的退化（过拟合）
| boosting思想的一种改进型adaboost方法在邮件过滤，文本分类中有很好的性能。

决策树
------------------------
| ID3 提出了初步的决策树算法，内部使用信息熵和信息增益来进行构建，每次迭代算则信息增益最大的特征属性作为分割属性。
| C4.5 提出了完整的决策树算法。使用信息增益率来取代ID3中的信息增益，在树的构造过程中会进行剪枝操作进行优化，能够自动完成对连续属性的离散化处理。
| CART (Classification And Regression Tree) 目前使用最多的决策树算法，选择那个使得划分后基尼指数最小的属性作为最优划分属性

| 一些资料
| https://www.jianshu.com/p/195d50a42ad5
|《李航 统计学习方法》 P60

**信息增益**

.. image:: ../../_static/machine_learning/熵.png
	:align: center
	:width: 500

.. image:: ../../_static/machine_learning/信息增益.png
	:align: center
	:width: 500

| 优点：
| 决策树构建速度快，实现简单。

| 缺点：
| 计算依赖于特征数目较多的特征，而属性值最多的属性并不一定最优。
| ID3算法不是递增算法。
| ID3算法是单变量决策树，对于特征属性之间的关系不会考虑。
| 抗噪性差。数据集中噪音点多可能会出现过拟合。
| 只适合小规模的数据集，需要将数据放到内存中。

**信息增益率**

.. image:: ../../_static/machine_learning/信息增益率.png
	:align: center
	:width: 500

g（D,A）是上面的的信息增益。g(D,A) = H(D) - H(D|A)

| 优点：
| 产生规则易于理解。
| 准确率较高。(因为考虑了连续值，数据越多拟合程度就越好。)
| 实现简单。

| 缺点：
| 对数据集需要进行多次扫描和排序，所以效率较低。(比如之前例子中收入的连续值，分割次数越多，需要扫描的次数也就越多，排序次数也越多。)
| 只适合小规模数据集，需要将数据放到内存中。

	
**决策树的剪枝**

.. image:: ../../_static/machine_learning/剪枝1.png
	:align: center
	:width: 500

设树的结点个数为|T|，则像正则化一样，损失函数加上 α|T|

**基尼系数**



.. image:: ../../_static/machine_learning/基尼系数1.png
	:align: center
	:width: 500
	
.. image:: ../../_static/machine_learning/基尼系数2.png
	:align: center
	:width: 500
	
	
其他常见问题
======================

如何解决机器学习中样本不均衡问题？
------------------------------------------
| •	通过过抽样和欠抽样解决样本不均衡

| 抽样是解决样本分布不均衡相对简单且常用的方法，包括过抽样和欠抽样两种。

| 过抽样
| 过抽样（也叫上采样、over-sampling）方法通过增加分类中少数类样本的数量来实现样本均衡，最直接的方法是简单复制少数类样本形成多条记录，这种方法的缺点是如果样本特征少而可能导致过拟合的问题；经过改进的过抽样方法通过在少数类中加入随机噪声、干扰数据或通过一定规则产生新的合成样本，例如SMOTE算法。

| 欠抽样
| 欠抽样（也叫下采样、under-sampling）方法通过减少分类中多数类样本的样本数量来实现样本均衡，最直接的方法是随机地去掉一些多数类样本来减小多数类的规模，缺点是会丢失多数类样本中的一些重要信息。

| 总体上，过抽样和欠抽样更适合大数据分布不均衡的情况，尤其是第一种（过抽样）方法应用更加广泛。

| •	通过正负样本的惩罚权重解决样本不均衡

| 通过正负样本的惩罚权重解决样本不均衡的问题的思想是在算法实现过程中，对于分类中不同样本数量的类别分别赋予不同的权重（一般思路分类中的小样本量类别权重高，大样本量类别权重低），然后进行计算和建模。
| 使用这种方法时需要对样本本身做额外处理，只需在算法模型的参数中进行相应设置即可。很多模型和算法中都有基于类别参数的调整设置，以scikit-learn中的SVM为例，通过在class_weight
| : {dict, 'balanced'}中针对不同类别针对不同的权重，来手动指定不同类别的权重。如果使用其默认的方法balanced，那么SVM会将权重设置为与不同类别样本数量呈反比的权重来做自动均衡处理，计算公式为：n_samples / (n_classes * np.bincount(y))。
| 如果算法本身支持，这种思路是更加简单且高效的方法。

| •	通过组合/集成方法解决样本不均衡
| 组合/集成方法指的是在每次生成训练集时使用所有分类中的小样本量，同时从分类中的大样本量中随机抽取数据来与小样本量合并构成训练集，这样反复多次会得到很多训练集和训练模型。最后在应用时，使用组合方法（例如投票、加权投票等）产生分类预测结果。
| 例如，在数据集中的正、负例的样本分别为100和10000条，比例为1:100。此时可以将负例样本（类别中的大量样本集）随机分为100份（当然也可以分更多），每份100条数据；然后每次形成训练集时使用所有的正样本（100条）和随机抽取的负样本（100条）形成新的数据集。如此反复可以得到100个训练集和对应的训练模型。
| 这种解决问题的思路类似于随机森林。在随机森林中，虽然每个小决策树的分类能力很弱，但是通过大量的“小树”组合形成的“森林”具有良好的模型预测能力。
| 如果计算资源充足，并且对于模型的时效性要求不高的话，这种方法比较合适。

| •	通过特征选择解决样本不均衡
| 上述几种方法都是基于数据行的操作，通过多种途径来使得不同类别的样本数据行记录均衡。除此以外，还可以考虑使用或辅助于基于列的特征选择方法。
| 一般情况下，样本不均衡也会导致特征分布不均衡，但如果小类别样本量具有一定的规模，那么意味着其特征值的分布较为均匀，可通过选择具有显著型的特征配合参与解决样本不均衡问题，也能在一定程度上提高模型效果。
| 提示 上述几种方法的思路都是基于分类问题解决的。实际上，这种从大规模数据中寻找罕见数据的情况，也可以使用非监督式的学习方法，例如使用One-class SVM进行异常检测。分类是监督式方法，前期是基于带有标签（Label）的数据进行分类预测；而采用非监督式方法，则是使用除了标签以外的其他特征进行模型拟合，这样也能得到异常数据记录。所以，要解决异常检测类的问题，先是考虑整体思路，然后再考虑方法模型。


数据挖掘中常见的「异常检测」算法有哪些？
------------------------------------------------
| https://www.zhihu.com/question/280696035
| 1. 无监督异常检测

| 如果归类的话，无监督异常检测模型可以大致分为：

| •	统计与概率模型（statistical and probabilistic and models）：主要是对数据的分布做出假设，并找出假设下所定义的“异常”，因此往往会使用极值分析或者假设检验。比如对最简单的一维数据假设高斯分布，然后将距离均值特定范围以外的数据当做异常点。而推广到高维后，可以假设每个维度各自独立，并将各个维度上的异常度相加。如果考虑特征间的相关性，也可以用马氏距离（mahalanobis distance）来衡量数据的异常度[12]。不难看出，这类方法最大的好处就是速度一般比较快，但因为存在比较强的“假设”，效果不一定很好。

| •	线性模型（linear models）：假设数据在低维空间上有嵌入，那么无法、或者在低维空间投射后表现不好的数据可以认为是离群点。举个简单的例子，PCA可以用于做异常检测[10]，一种方法就是找到k个特征向量（eigenvector），并计算每个样本再经过这k个特征向量投射后的重建误差（reconstruction error），而正常点的重建误差应该小于异常点。同理，也可以计算每个样本到这k个选特征向量所构成的超空间的加权欧氏距离（特征值越小权重越大）。在相似的思路下，我们也可以直接对协方差矩阵进行分析，并把样本的马氏距离（在考虑特征间关系时样本到分布中心的距离）作为样本的异常度，而这种方法也可以被理解为一种软性（Soft PCA） [6]。同时，另一种经典算法One-class SVM[3]也一般被归类为线性模型。

| •	基于相似度衡量的模型（proximity based models）：异常点因为和正常点的分布不同，因此相似度较低，由此衍生了一系列算法通过相似度来识别异常点。比如最简单的K近邻就可以做异常检测，一个样本和它第k个近邻的距离就可以被当做是异常值，显然异常点的k近邻距离更大。同理，基于密度分析如LOF [1]、LOCI和LoOP主要是通过局部的数据密度来检测异常。显然，异常点所在空间的数据点少，密度低。相似的是，Isolation Forest[2]通过划分超平面来计算“孤立”一个样本所需的超平面数量（可以想象成在想吃蛋糕上的樱桃所需的最少刀数）。在密度低的空间里（异常点所在空间中），孤例一个样本所需要的划分次数更少。另一种相似的算法ABOD[7]是计算每个样本与所有其他样本对所形成的夹角的方差，异常点因为远离正常点，因此方差变化小。换句话说，大部分异常检测算法都可以被认为是一种估计相似度，无论是通过密度、距离、夹角或是划分超平面。通过聚类也可以被理解为一种相似度度量，比较常见不再赘述。

| •	集成异常检测与模型融合：在无监督学习时，提高模型的鲁棒性很重要，因此集成学习就大有用武之地。比如上面提到的Isolation Forest，就是基于构建多棵决策树实现的。最早的集成检测框架feature bagging[9]与分类问题中的随机森林（random forest）很像，先将训练数据随机划分（每次选取所有样本的d/2-d个特征，d代表特征数），得到多个子训练集，再在每个训练集上训练一个独立的模型（默认为LOF）并最终合并所有的模型结果（如通过平均）。值得注意的是，因为没有标签，异常检测往往是通过bagging和feature bagging比较多，而boosting比较少见。boosting情况下的异常检测，一般需要生成伪标签，可参靠[13, 14]。集成异常检测是一个新兴但很有趣的领域，综述文章可以参考[16, 17, 18]。

| •	特定领域上的异常检测：比如图像异常检测 [21]，顺序及流数据异常检测（时间序列异常检测）[22]，以及高维空间上的异常检测 [23]，比如前文提到的Isolation Forest就很适合高维数据上的异常检测。


| 维度低的时候，二维 可以直接用高斯函数的3希格玛原则，低维，KNN，实际上是计算相似度，再高维的话可以isolation Forrest， 之后两个月我可以学一下  （pca或者autoencoder降维 再高斯）

sklearn

https://scikit-learn.org/stable/modules/outlier_detection.html#overview-of-outlier-detection-methods


上采用 & 下采样
---------------------
https://www.cnblogs.com/zhanjiahui/p/11643544.html

https://www.jianshu.com/p/fd9e2166cfcc


几种距离度量方法比较
-----------------------
https://blog.csdn.net/J_Boom/article/details/86763024


欧氏距离

.. image:: ../../_static/machine_learning/欧氏距离.png
	:align: center
	:width: 400

曼哈顿距离

.. image:: ../../_static/machine_learning/曼哈顿距离.png
	:align: center
	:width: 400

切比雪夫距离

.. image:: ../../_static/machine_learning/切比雪夫距离.png
	:align: center
	:width: 400

| 马氏距离
| 就是做个PCA 排除均值和方差的影响

.. image:: ../../_static/machine_learning/马氏距离.png
	:align: center
	:width: 400

余弦距离 略

汉明距离(Hamming Distance)  就是编辑距离

杰卡德距离(Jaccard Distance)

.. image:: ../../_static/machine_learning/杰卡德距离.png
	:align: center

相关距离(Correlation distance)

.. image:: ../../_static/machine_learning/相关距离.png
	:align: center

启发式算法
-----------------------------
通俗的解释就是利用类似仿生学的原理，将自然、动物中的一些现象抽象成为算法处理相应问题。当一个问题是NP难问题时，是无法求解到最优解的，
因此，用一种相对好的求解算法，去尽可能逼近最优解，得到一个相对优解，在很多实际情况中也是可以接受的。

举例：模拟退火算法（SA）、遗传算法（GA）、蚁群算法（ACO）、人工神经网络（ANN）



生成式和判别式 算法
----------------------------
.. image:: ../../_static/machine_learning/scpb.png
	:align: center
	:width: 400

机器学习“判定模型”和“生成模型”有什么区别？ https://www.zhihu.com/question/20446337/answer/256466823


举一个例子：判别式模型举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，
然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。

生成式模型举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，
然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。


细细品味上面的例子，判别式模型是根据一只羊的特征可以直接给出这只羊的概率（比如logistic regression，这概率大于0.5时则为正例，否则为反例），
而生成式模型是要都试一试，最大的概率的那个就是最后结果

在机器学习中任务是从属性X预测标记Y，判别模型求的是P(Y|X)，即后验概率；
而生成模型最后求的是P(X,Y)，即联合概率。从本质上来说：判别模型之所以称为“判别”模型，是因为其根据X“判别”Y；而生成模型之所以称为“生成”模型，
是因为其预测的根据是联合概率P(X,Y)，而联合概率可以理解为“生成”(X,Y)样本的概率分布（或称为 依据）；具体来说，机器学习已知X，从Y的候选集合中选出一个来，
可能的样本有(X,Y_1), (X,Y_2), (X,Y_3),……，(X,Y_n),实际数据是如何“生成”的依赖于P(X,Y)，那么最后的预测结果选哪一个Y呢？那就选“生成”概率最大的那个吧~

.. image:: ../../_static/machine_learning/生成式判别式.png
	:align: center


L0 L1 L2 正则化
-------------------
| L0正则化的值是模型参数中非零参数的个数。
| L1正则化表示各个参数绝对值之和。
| L2正则化标识各个参数的平方的和的开方值。

| L1 和 L2：
| •	L2正则相比于L1正则来说，得到的解比较平滑（不是稀疏），但是同样能够保证解中接近于0（但不是等于0，所以相对平滑）的维度比较多，降低模型的复杂度。
| •	L2 计算起来更方便，而 L1 在特别是非稀疏向量上的计算效率就很低；
| •	L1 最重要的一个特点，输出稀疏，会把不重要的特征直接置零，而 L2 则不会；
| •	L2 有唯一解，而 L1 不是。


两种正则化会导致模型最后有什么不同，为什么会有这种现象

L1 和 L2 正则的区别是什么？

这个问题可以从两个角度去解释，概率角度和微积分角度。

首先是概率角度。
正则项来自于对数据的先验知识，这个先验知识的概率密度函数定义为 p(x)。如果我们认为，数据是服从高斯分布的，那么就应该在代价函数中加入数据先验P(x),
一般由于推导和计算方便会加入对数似然,也就是log(P(x)),然后再去优化,如果你去看看高斯分布的概率密度函数P(x),你会发现取对数后的log(P(x))就剩下一个平方项了,这就是L2范式的由来--高斯先验.

同样,如果你认为你的数据是稀疏的,不妨就认为它来自某种laplace分布.不知你是否见过laplace分布的概率密度函数，laplace分布是尖尖的分布,
是不是很像一个pulse?从这张图上,你应该就能看出,服从laplace分布的数据就是稀疏的了，如果取对数,剩下的是一个一次项|x-u|,这就是L1范式.
所以用L1范式去正则,就假定了你的数据是laplace分布,是稀疏的.

微积分角度。

一个优化问题的最优解，一般是在导数 = 0 的位置上。

如果原有模型的参数不是稀疏的，那么就意味着损失函数 f(x) 在求导时，0 点的导数不等于 0 ，即 f'(0) != 0，否则 如果等于 0 的话，那么 0 会是一个局部解导致模型稀疏。

此时，如果加上一个 L2 正则项，原有的 损失函数就变成了 f(x) + C||x||^2， 它在 0 点的导数就是 f'(0) + 2Cx (x = 0)。 因为 f'(0) != 0 所以整个式子不等于 0 ，所以 x = 0 不是极值点。

如果不是 L2， 是 L1，那么 损失函数就变成了 f(x) + C|x|，其 0 点 左导数 -C+f'(0), 右导数是 C+f'(0) ， 从而当C > |f'(0)|的时候，次梯度集合是包含0点的，
而根据次梯度的定义，这个时候 x=0 即为最小值。

参数稀疏有什么好处
------------------------------
1）特征选择(Feature Selection)： 大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，xi的大部分元素（也就是特征）
都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，
这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。

2）可解释性(Interpretability)： 另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，
也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：y=w1*x1+w2*x2+…+w1000*x1000+b
（当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w*就只有很少的非零元素，例如只有5个非零的wi，
那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。
但如果1000个wi都非0，医生面对这1000种因素.

Rank Averaging
-----------------------------
.. image:: ../../_static/machine_learning/Rank_Averaging.png
	:align: center

数据清洗
-----------------------
| 数据清洗(Data cleaning)– 对数据进行重新审查和校验的过程，目的在于删除重复信息、纠正存在的错误，并提供数据一致性。
| 按照一定的规则把“脏”的“洗掉”，指发现并纠正数据文件中可识别的错误的最后一道程序，包括检查数据一致性，处理无效值和缺失值等。
| 不符合要求的数据主要是有不完整的数据、错误的数据、重复的数据三大类。
| 数据清洗是与问卷审核不同，录入后的数据清理一般是由计算机而不是人工完成

进程与线程
-------------------
先来个直观的解释。核心是 一个进程可以是多线程 （可以有多条线）

.. image:: ../../_static/machine_learning/进程线程.png
	:align: center


https://www.zhihu.com/question/25532384/answer/1130818664 这个解答说的很好，解释的具体，而且面试题也涉及了

| 核心：
| 进程是资源分配的基本单位；线程是程序执行的基本单位。
| 一个进程可以包含若干个线程。

| 进程/线程如何通信
| 答：进程可以通过管道、套接字、信号交互、共享内存、消息队列等等进行通信；而线程本身就会共享内存，指针指向同一个内容，交互很容易。

推荐系统
=====================
light GBM, Deepfm,Wide&Deep,YoutubeNet, PNN

